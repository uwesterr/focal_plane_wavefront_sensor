{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 Install, Import, and Log in"
      ],
      "metadata": {
        "id": "PIIQxWeVW4Pj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 0️⃣: Install W&B"
      ],
      "metadata": {
        "id": "wmlhYoBlOxYd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "%%capture\n",
        "#!pip install wandb\n",
        "!pip install pandas"
      ],
      "outputs": [],
      "metadata": {
        "id": "sAZBTFNQq0ys"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 1️⃣: Import W&B and Login"
      ],
      "metadata": {
        "id": "Tu-KHLAeO3wi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "\n",
        "\n",
        "#%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "id": "jkWTZxIyysDm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "#wandb.init()  # defaults are over-ridden during the sweep\n",
        "\n",
        "\n",
        "#wandb.login()"
      ],
      "outputs": [],
      "metadata": {
        "id": "XmVkQbw_q_07"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "fluxData_df =pd.read_hdf(\"data/fluxData_df.h5\", key=\"fluxData_df\")\n",
        "\n",
        "zernikeData_df =pd.read_hdf(\"data/zernikeData_df.h5\", key=\"zernikeData_df\")"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read data in"
      ],
      "metadata": {
        "id": "hNw4gP_Oqx7c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 👩‍🍳 Prepare Dataset"
      ],
      "metadata": {
        "id": "Nhe7pVMlwv4H"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# Prepare the training dataset\n",
        "X = fluxData_df\n",
        "y = zernikeData_df\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42)\n"
      ],
      "outputs": [],
      "metadata": {
        "id": "xnxsNbPmMvqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Normalize data\n",
        "as shown in https://keras.io/guides/preprocessing_layers/#normalizing-numerical-features "
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "\n",
        "x_train_norm = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
        "x_train_norm"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build simple Model"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# AoModel = keras.Sequential([\n",
        "#      keras.layers.InputLayer(19, name=\"digits\"),\n",
        "#      keras.layers.Dense(2000, activation=\"relu\"),\n",
        "#      keras.layers.Dense(1050, activation=\"relu\"),\n",
        "#      keras.layers.Dense(100, activation=\"relu\"),\n",
        "#      keras.layers.Dense(9, activation=\"linear\", name=\"predictions\"),\n",
        "\n",
        "# ])\n",
        "# AoModel.summary()"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "# batch_size = 128\n",
        "# epochs = 200\n",
        "\n",
        "\n",
        "#     # optimizer='sgd',\n",
        "#     # loss='mse',\n",
        "#     # metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "\n",
        "\n",
        "# AoModel.compile(loss= keras.losses.MeanSquaredError(), optimizer=\"adam\", metrics= [tf.keras.metrics.RootMeanSquaredError()])\n",
        "# #AoModel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, verbose = 2,  callbacks=[WandbCallback()])\n",
        "\n",
        "# #AoModel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[WandbCallback()])"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🧠 Define the wandb sweep"
      ],
      "metadata": {
        "id": "ftU5d82stSdV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"AoKerasStudio.ipynb\"\n",
        "\n",
        "sweep_config = {\n",
        "    \"method\": \"random\", # try grid or random\n",
        "    \"metric\": {\n",
        "        \"name\": \"val_root_mean_squared_error\",\n",
        "        \"goal\": \"minimize\"\n",
        "    },\n",
        "    \"parameters\": {\n",
        "\n",
        "    \"learning_rate\" :{\n",
        "        \"values\": [ 0.005, 0.001]\n",
        "        }, \n",
        "    \"lrFactor\": {\n",
        "        \"values\": [ 0.2, 0.5]\n",
        "    },                  \n",
        "  \n",
        "    \"batch_size\": {\n",
        "        \"values\": [128]\n",
        "    },\n",
        "    \"epochs\": {\n",
        "        \"values\": [100]\n",
        "    }, \n",
        "    \"NoLayers\": {\n",
        "        \"values\": [3, 4]\n",
        "    },     \n",
        "    \n",
        "    \"layer1\": {\n",
        "        \"values\": [2000, 3000, 4000]\n",
        "    },\n",
        "    \"layer2\": {\n",
        "        \"values\": [1050, 2050]\n",
        "    },     \n",
        "    \"layer4\": {\n",
        "        \"values\": [200, 400, 1050, 2050]\n",
        "    },             \n",
        "    \"layer3\": {\n",
        "        \"values\": [200, 400, 1050, 2050]    }                \n",
        "    }\n",
        "}"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "## Define training loop"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def train():\n",
        " \n",
        "  wandb.init(tags=[\"SecondSweep3LayersBayesMethod\"])  # defaults are over-ridden during the sweep\n",
        "  config = wandb.config\n",
        "#   AoModel = keras.Sequential([\n",
        "#      keras.layers.InputLayer(19, name=\"digits\"),\n",
        "#      keras.layers.Dense(config.layer1, activation=\"relu\"),\n",
        "#      keras.layers.Dense(config.layer2, activation=\"relu\"),\n",
        "#      keras.layers.Dense(config.layer3, activation=\"relu\"),\n",
        "#      keras.layers.Dense(9, activation=\"linear\", name=\"predictions\"),\n",
        "\n",
        "# ])\n",
        "  inputs = keras.Input(shape=(19,))\n",
        "  Layer1 = layers.Dense(config.layer1, activation=\"relu\", name = \"Layer1\")\n",
        "  x = Layer1(inputs)\n",
        "  x = layers.Dense(config.layer2, activation=\"relu\", name = \"Layer2\")(x)\n",
        "  if(config.NoLayers >3):\n",
        "      x = layers.Dense(config.layer3, activation=\"relu\", name = \"Layer3\")(x)\n",
        "  outputs = layers.Dense(9, name = \"Output\")(x)  \n",
        "  x = layers.Dense(config.layer4, activation=\"relu\", name = \"Layer4\")(x)\n",
        "\n",
        "  AoModel = keras.Model(inputs=inputs, outputs=outputs, name=\"AOModel\")\n",
        "\n",
        "  #AoFunctionalModel.summary()\n",
        "\n",
        "  earlyStopping = keras.callbacks.EarlyStopping(monitor = \"val_loss\", patience =10)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=config.lrFactor,\n",
        "                                patience=5, min_lr=0.000001, verbose=1, cooldown= 5)\n",
        "\n",
        "  opt = keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
        "  AoModel.compile(loss= keras.losses.MeanSquaredError(),  optimizer=opt, metrics= [tf.keras.metrics.RootMeanSquaredError()])\n",
        "  AoModel.fit(x_train_norm, y_train, batch_size=config.batch_size, epochs=config.epochs,validation_split = 0.2, verbose = 2, callbacks=[reduce_lr, earlyStopping, WandbCallback()])\n",
        "\n",
        "#AoModel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[WandbCallback()])\n",
        "  #AoModel.compile(loss= keras.losses.MeanSquaredError(), optimizer=\"adam\", metrics= [tf.keras.metrics.RootMeanSquaredError()])\n",
        "\n",
        "  #AoModel.fit(x_train_norm, y_train, batch_size=config.batch_size, epochs=config.epochs, verbose = 2,validation_split = 0.2 , callbacks=[WandbCallback()])\n",
        "  #wandb.log({\"learning_rate\": \"learning_rate\"})"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initialize sweep"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "sweep_id = wandb.sweep(sweep_config, entity = \"uwe-sterr\",project=\"KerasAoSweep\")\n",
        "wandb.run"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run sweep"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "wandb.agent(sweep_id, train, count=400)"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Hyperparameter Optimization in TensorFlow using W&B Sweeps",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "7240fa07bd5f0492db6e5998fcde1467c49f289639e3a06c91ae7c487c9ff707"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}