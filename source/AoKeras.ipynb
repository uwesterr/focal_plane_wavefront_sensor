{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import pyarrow.feather as feather\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "#from tensorflow.keras.layers.experimental import preprocessing\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# W & B test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# import wandb\n",
    "# from wandb.keras import WandbCallback\n",
    "# !wandb login\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Prepare the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# fluxData_df = feather.read_feather('data/fluxData.feather')\n",
    "# # zernikeData_df = feather.read_feather('data/zernikeData.feather')\n",
    "# fluxData_df\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## import data as h5"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fluxData_df =pd.read_hdf(\"data/fluxData_df.h5\", key=\"fluxData_df\")\n",
    "\n",
    "zernikeData_df =pd.read_hdf(\"data/zernikeData_df.h5\", key=\"zernikeData_df\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Prepare the training dataset\n",
    "X = fluxData_df\n",
    "y = zernikeData_df\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Normalize data\n",
    "as shown in https://keras.io/guides/preprocessing_layers/#normalizing-numerical-features "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "x_train_norm = (x_train - x_train.mean(axis=0)) / x_train.std(axis=0)\n",
    "x_train_norm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build Model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "from tensorflow import keras\n",
    "AoModel = keras.Sequential([\n",
    "     keras.layers.InputLayer(19, name=\"digits\"),\n",
    "     keras.layers.Dense(2000, activation=\"relu\"),\n",
    "     keras.layers.BatchNormalization(),\n",
    "     keras.layers.Dense(1050, activation=\"relu\"),\n",
    "     keras.layers.BatchNormalization(),\n",
    "     keras.layers.Dense(100, activation=\"relu\"),\n",
    "     keras.layers.BatchNormalization(),\n",
    "     keras.layers.Dense(9, activation=\"linear\", name=\"predictions\"),\n",
    "\n",
    "])\n",
    "AoModel.summary()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 2000)              40000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 2000)              8000      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1050)              2101050   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1050)              4200      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 100)               105100    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 9)                 909       \n",
      "=================================================================\n",
      "Total params: 2,259,659\n",
      "Trainable params: 2,253,359\n",
      "Non-trainable params: 6,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Compile and run model "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "batch_size = 128\n",
    "epochs = 200\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "AoModel.compile(loss= keras.losses.MeanSquaredError(),  optimizer=opt, metrics= [tf.keras.metrics.RootMeanSquaredError()])\n",
    "AoModel.fit(x_train_norm, y_train, batch_size=batch_size, epochs=epochs,validation_split = 0.2, verbose = 2)\n",
    "\n",
    "#AoModel.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=[WandbCallback()])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train on 42292 samples, validate on 10574 samples\n",
      "Epoch 1/200\n",
      "42292/42292 - 3s - loss: 0.0480 - root_mean_squared_error: 0.2190 - val_loss: 0.0241 - val_root_mean_squared_error: 0.1552\n",
      "Epoch 2/200\n",
      "42292/42292 - 2s - loss: 0.0069 - root_mean_squared_error: 0.0831 - val_loss: 0.0050 - val_root_mean_squared_error: 0.0710\n",
      "Epoch 3/200\n",
      "42292/42292 - 2s - loss: 0.0048 - root_mean_squared_error: 0.0693 - val_loss: 0.0040 - val_root_mean_squared_error: 0.0635\n",
      "Epoch 4/200\n",
      "42292/42292 - 2s - loss: 0.0038 - root_mean_squared_error: 0.0620 - val_loss: 0.0027 - val_root_mean_squared_error: 0.0521\n",
      "Epoch 5/200\n",
      "42292/42292 - 2s - loss: 0.0033 - root_mean_squared_error: 0.0576 - val_loss: 0.0025 - val_root_mean_squared_error: 0.0503\n",
      "Epoch 6/200\n",
      "42292/42292 - 2s - loss: 0.0029 - root_mean_squared_error: 0.0539 - val_loss: 0.0026 - val_root_mean_squared_error: 0.0509\n",
      "Epoch 7/200\n",
      "42292/42292 - 2s - loss: 0.0026 - root_mean_squared_error: 0.0513 - val_loss: 0.0019 - val_root_mean_squared_error: 0.0430\n",
      "Epoch 8/200\n",
      "42292/42292 - 2s - loss: 0.0024 - root_mean_squared_error: 0.0493 - val_loss: 0.0017 - val_root_mean_squared_error: 0.0410\n",
      "Epoch 9/200\n",
      "42292/42292 - 2s - loss: 0.0023 - root_mean_squared_error: 0.0481 - val_loss: 0.0018 - val_root_mean_squared_error: 0.0423\n",
      "Epoch 10/200\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7240fa07bd5f0492db6e5998fcde1467c49f289639e3a06c91ae7c487c9ff707"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}