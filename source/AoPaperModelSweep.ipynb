{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIIQxWeVW4Pj"
      },
      "source": [
        "# üöÄ Install, Import, and Log in"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmlhYoBlOxYd"
      },
      "source": [
        "### Step 0Ô∏è‚É£: Install W&B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAZBTFNQq0ys"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "#!pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tu-KHLAeO3wi"
      },
      "source": [
        "### Step 1Ô∏è‚É£: Import W&B and Login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jkWTZxIyysDm"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import pyarrow.feather as feather\n",
        "from sklearn.model_selection import train_test_split \n",
        "from tensorflow.keras import regularizers\n",
        "import math\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XmVkQbw_q_07"
      },
      "outputs": [],
      "source": [
        "import wandb\n",
        "from wandb.keras import WandbCallback\n",
        "\n",
        "\n",
        "!wandb.login()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNw4gP_Oqx7c"
      },
      "source": [
        "Read data in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fluxData_df = feather.read_feather('data/fluxData.feather')\n",
        "zernikeData_df = feather.read_feather('data/zernikeData.feather')\n",
        "#fluxData_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nhe7pVMlwv4H"
      },
      "source": [
        "# üë©‚Äçüç≥ Prepare Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnxsNbPmMvqr"
      },
      "outputs": [],
      "source": [
        "# Prepare the training dataset\n",
        "X = fluxData_df\n",
        "y = zernikeData_df\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def Model():\n",
        "    inputs = keras.Input(shape=(19,), name=\"digits\")\n",
        "    x1 = keras.layers.Dense(wandb.config.layer1, activation=\"relu\", name = \"conv1D_1\")(inputs)\n",
        "    x2 = keras.layers.Dense(wandb.config.layer2, activation=\"relu\")(x1)\n",
        "    x3 = keras.layers.Dense(wandb.config.layer3, activation=\"relu\")(x2)\n",
        "    outputs = keras.layers.Dense(9, name=\"predictions\")(x3)\n",
        "\n",
        "    return keras.Model(inputs=inputs, outputs=outputs)\n",
        "    \n",
        "#AoSweepModel = Model()    \n",
        "#AoSweepModel.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#keras.utils.plot_model(AoSweepModel, show_shapes=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reshape training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "input_train = x_train.to_numpy()[:,:,np.newaxis]\n",
        "input_test = x_test.to_numpy()[:,:,np.newaxis]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Train simple model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def training():\n",
        "    run = wandb.init(project=\"Ao_Paper_Model\",\n",
        "    notes=\"Learning rate scheduler\",\n",
        "    tags=['Ao', \"Paper\", \"lr_schedule\" ,\"1DConv\"])\n",
        "    AoSweepModel = Model() \n",
        "    opt = keras.optimizers.Adam(learning_rate= wandb.config.learning_rate)\n",
        "    AoSweepModel.compile(optimizer= opt,  loss=\"mse\", metrics=[keras.metrics.RootMeanSquaredError()])\n",
        "    AoSweepModel.fit(input_train, y_train, batch_size= 128, epochs= wandb.config.epochs, validation_split=0.1, callbacks=[WandbCallback()])\n",
        "    callbacks=[WandbCallback()]\n",
        "    trainPredict = AoSweepModel.predict(input_train)\n",
        "    trainError = trainPredict - y_train\n",
        "    tmp = trainError.to_numpy().flatten()\n",
        "    error = np.sqrt(np.sum(tmp**2)/tmp.size)\n",
        "    wandb.log({\"error\": error})\n",
        "#training()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define sweep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"AoPaperModelSweep.ipynb\"\n",
        "sweep_config = {\n",
        "  \"name\" : \"PaperVersionSweepKeras\",\n",
        "  \"method\" : \"random\",\n",
        "    \"metric\": {\n",
        "      \"name\": \"error\",\n",
        "      \"goal\": \"minimize\"   \n",
        "    },\n",
        "  \"parameters\" : {\n",
        "    \"epochs\" : {\n",
        "      \"values\" : [20, 40]\n",
        "    },\n",
        "    \"layer1\" : {\n",
        "      \"values\" : [4000, 2000, 500]\n",
        "    },\n",
        "    \"layer2\" : {\n",
        "      \"values\" : [800, 300]\n",
        "    },\n",
        "    \"layer3\" : {\n",
        "      \"values\" : [100, 50]\n",
        "    },\n",
        "    \"learning_rate\" :{\n",
        "      \"min\": 1e-4,\n",
        "      \"max\": 5e-3\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "count = 100 # number of runs to execute\n",
        "wandb.agent(sweep_id, function=training, count=count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Hyperparameter Optimization in TensorFlow using W&B Sweeps",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "7240fa07bd5f0492db6e5998fcde1467c49f289639e3a06c91ae7c487c9ff707"
    },
    "kernelspec": {
      "display_name": "Python 3.8.8 64-bit ('base': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}