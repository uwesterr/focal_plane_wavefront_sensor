{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Learn about class and pytorch\n",
    "runs with 3.8.2 on linux and 3.8.8 on mac"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup tensorboard"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install tensorflow --upgrade\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pyarrow.feather as feather\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def build_dataset(batchSizeTrain, batchsizeValid):\n",
    "    fluxData_df = feather.read_feather('data/fluxData.feather')\n",
    "    # normalize input data\n",
    "    fluxData_df_norm = (fluxData_df - fluxData_df.mean(axis=0)) / fluxData_df.std(axis=0)\n",
    "    zernikeData_df = feather.read_feather('data/zernikeData.feather')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(fluxData_df_norm, zernikeData_df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_target = torch.tensor(y_train.values.astype(np.float32))\n",
    "    trainInput = torch.tensor(X_train.values.astype(np.float32))\n",
    "\n",
    "    train_tensor = torch.utils.data.TensorDataset(trainInput, train_target) \n",
    "    loaderTrain = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batchSizeTrain, shuffle = True)\n",
    "\n",
    "\n",
    "    valid_target = torch.tensor(y_val.values.astype(np.float32))\n",
    "    validInput = torch.tensor(X_val.values.astype(np.float32))\n",
    "\n",
    "    train_tensor = torch.utils.data.TensorDataset(validInput, valid_target) \n",
    "    loaderValid = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batchsizeValid, shuffle = True)\n",
    "    return loaderTrain, loaderValid\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build AO network as class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(19,2000)\n",
    "        self.linear2 = nn.Linear(2000,1050)\n",
    "        self.linear3 = nn.Linear(1050,100)\n",
    "        self.out = nn.Linear(100,9)\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'lrelu': nn.LeakyReLU()\n",
    "    })\n",
    "\n",
    "    def forward(self, x, act = \"relu\"):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.activations[act](x)\n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        #x = self.activations[act](x)\n",
    "        x = self.linear3(x)\n",
    "        #x = self.activations[act](x)\n",
    "        x = F.relu(x)\n",
    "        x = self.out(x)\n",
    "        return(x)\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train(config=None):\n",
    "    ClassNetwork = Net()\n",
    "    print(ClassNetwork)\n",
    "    optimizer = optim.AdamW(ClassNetwork.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.8, cooldown=20,\n",
    "    verbose=True)\n",
    "    loaderTrain, loaderValid =build_dataset(128,128)\n",
    "    epochs = 800\n",
    "    for epoch in range(epochs):\n",
    "        ClassNetwork.train()\n",
    "        for i, data in enumerate(loaderTrain,0):\n",
    "            input, labels = data\n",
    "            optimizer.zero_grad()\n",
    "            outputs = ClassNetwork(input, \"relu\")\n",
    "            loss = nn.MSELoss()\n",
    "            loss =loss(ClassNetwork(input, \"relu\"), labels)\n",
    "    # ⬅ Backward pass + weight update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        for i, data in enumerate(loaderValid,0):\n",
    "            ClassNetwork.eval()\n",
    "            lossVal = nn.MSELoss()            \n",
    "            lossVal =lossVal(ClassNetwork(input, \"relu\"), labels)\n",
    "            RmsLossValid=torch.sqrt(loss) \n",
    "        \n",
    "        scheduler.step(RmsLossValid.item())            \n",
    "        print(\"epoch: \", epoch, \"loss: \", \"%.4f\" % loss.item() ,\"RmsLossValid: \" , \"%.4f\" % RmsLossValid.item())  \n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "        writer.add_scalar('RmsLossValid/valid', RmsLossValid.item(), epoch)\n",
    "    data, labels = next(iter(loaderValid))\n",
    "    writer.add_graph(ClassNetwork, data  )\n",
    "    writer.close"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\"\"\" ClassNetwork = Net()\n",
    "print(ClassNetwork)\n",
    "optimizer = optim.AdamW(ClassNetwork.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "loaderTrain, loaderValid =build_dataset(128,128)\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "    ClassNetwork.train()\n",
    "    for i, data in enumerate(loaderTrain,0):\n",
    "        input, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ClassNetwork(input, \"relu\")\n",
    "        loss = nn.MSELoss()\n",
    "        loss =loss(ClassNetwork(input, \"relu\"), labels)\n",
    "# ⬅ Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for i, data in enumerate(loaderValid,0):\n",
    "        ClassNetwork.eval()\n",
    "        lossVal = nn.MSELoss()            \n",
    "        lossVal =lossVal(ClassNetwork(input, \"relu\"), labels)\n",
    "        RmsLossValid=torch.sqrt(loss) \n",
    "        scheduler.step(RmsLossValid)   \n",
    "    print(optimizer.param_groups[0][\"lr\"])\n",
    "    print(\"epoch: \", epoch, \"loss: \", \"%.4f\" % loss.item() ,\"RmsLossValid: \" , \"%.4f\" % RmsLossValid.item())  \n",
    " \"\"\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# ClassNetwork = Net()\n",
    "\n",
    "# loaderTrain, loaderValid =build_dataset(1024,1024)\n",
    "# data, labels = next(iter(loaderValid))\n",
    "# ClassNetwork( data, \"relu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "train()"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "643de512da3ef9692daa896915c9c6edbec44805ccf75c0ed51aafb5eb9790df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}