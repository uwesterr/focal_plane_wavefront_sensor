{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Learn about class and pytorch\n",
    "runs with 3.8.2 on linux and 3.8.8 on mac"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Setup tensorboard"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install tensorflow --upgrade\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# setup wandb"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "import wandb\n",
    "wandb.init(project=\"testPytorch\")"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Finishing last run (ID:105fa8we) before initializing another..."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 22955<br/>Program ended successfully."
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Label(value=' 0.03MB of 0.03MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8ab26a8862ad404aa8859e1eec76e634"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find user logs for this run at: <code>/home/uwe/Documents/AoSydneyGitHub/focal_plane_wavefront_sensor/source/wandb/run-20210722_110514-105fa8we/logs/debug.log</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Find internal logs for this run at: <code>/home/uwe/Documents/AoSydneyGitHub/focal_plane_wavefront_sensor/source/wandb/run-20210722_110514-105fa8we/logs/debug-internal.log</code>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Synced 7 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">sleek-wildflower-18</strong>: <a href=\"https://wandb.ai/uwe-sterr/testPytorch/runs/105fa8we\" target=\"_blank\">https://wandb.ai/uwe-sterr/testPytorch/runs/105fa8we</a><br/>\n",
       "                "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "...Successfully finished last run (ID:105fa8we). Initializing new run:<br/><br/>"
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-07-22 11:05:37.990910: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-22 11:05:37.990928: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.11.0<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">light-gorge-19</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/uwe-sterr/testPytorch\" target=\"_blank\">https://wandb.ai/uwe-sterr/testPytorch</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/uwe-sterr/testPytorch/runs/37b926xv\" target=\"_blank\">https://wandb.ai/uwe-sterr/testPytorch/runs/37b926xv</a><br/>\n",
       "                Run data is saved locally in <code>/home/uwe/Documents/AoSydneyGitHub/focal_plane_wavefront_sensor/source/wandb/run-20210722_110533-37b926xv</code><br/><br/>\n",
       "            "
      ]
     },
     "metadata": {}
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f6eff6dda90>"
      ],
      "text/html": [
       "<h1>Run(37b926xv)</h1><iframe src=\"https://wandb.ai/uwe-sterr/testPytorch/runs/37b926xv\" style=\"border:none;width:100%;height:400px\"></iframe>"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "source": [
    "import pyarrow.feather as feather\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "def build_dataset(batchSizeTrain, batchsizeValid):\n",
    "    fluxData_df = feather.read_feather('data/fluxData.feather')\n",
    "    # normalize input data\n",
    "    fluxData_df_norm = (fluxData_df - fluxData_df.mean(axis=0)) / fluxData_df.std(axis=0)\n",
    "    zernikeData_df = feather.read_feather('data/zernikeData.feather')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(fluxData_df_norm, zernikeData_df, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "    train_target = torch.tensor(y_train.values.astype(np.float32))\n",
    "    trainInput = torch.tensor(X_train.values.astype(np.float32))\n",
    "\n",
    "    train_tensor = torch.utils.data.TensorDataset(trainInput, train_target) \n",
    "    loaderTrain = torch.utils.data.DataLoader(dataset = train_tensor, batch_size = batchSizeTrain, shuffle = True)\n",
    "\n",
    "\n",
    "    valid_target = torch.tensor(y_val.values.astype(np.float32))\n",
    "    validInput = torch.tensor(X_val.values.astype(np.float32))\n",
    "\n",
    "    valid_tensor = torch.utils.data.TensorDataset(validInput, valid_target) \n",
    "    loaderValid = torch.utils.data.DataLoader(dataset = valid_tensor, batch_size = batchsizeValid, shuffle = True)\n",
    "    return loaderTrain, loaderValid\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Build data loader"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Build AO network as class"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "config = {\n",
    "\"Layer1\" : 2000,\n",
    "\"Layer2\" : 12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "source": [
    "config[\"Layer1\"] "
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "metadata": {},
     "execution_count": 102
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "source": [
    "import torch.nn.functional as F\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, Layer1):\n",
    "        super(Net, self).__init__()\n",
    "        self.linear1 = nn.Linear(19,Layer1)\n",
    "        self.linear2 = nn.Linear(Layer1,100)\n",
    "        self.linear3 = nn.Linear(1050,100)\n",
    "        self.linear4 = nn.Linear(400,400)        \n",
    "        self.out = nn.Linear(100,9)\n",
    "        self.dropout = nn.Dropout(p=0.0001)\n",
    "        self.activations = nn.ModuleDict({\n",
    "            'relu': nn.ReLU(),\n",
    "            'lrelu': nn.LeakyReLU()\n",
    "    })\n",
    "\n",
    "    def forward(self, x, act = \"relu\"):\n",
    "        x = self.linear1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)        \n",
    "        x = self.linear2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)        \n",
    "\n",
    "        # x = self.linear3(x)\n",
    "        # x = F.relu(x)\n",
    "        # x = self.dropout(x)        \n",
    "\n",
    "      #  x = self.linear4(x)\n",
    "      #  x = F.relu(x) \n",
    "       # x = self.dropout(x)        \n",
    "        x = self.out(x)\n",
    "        return(x)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "source": [
    "def train(config=None):\n",
    "    print(config)\n",
    "    ClassNetwork = Net(config[\"Layer1\"]).to(device)\n",
    "    wandb.watch(ClassNetwork, log_freq=10)\n",
    "\n",
    "    optimizer = optim.AdamW(ClassNetwork.parameters(), lr=0.001)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, cooldown=5, patience=5,\n",
    "    verbose=True)\n",
    "    loaderTrain, loaderValid =build_dataset(128,128)\n",
    "    epochs = 100\n",
    "    for epoch in range(epochs):\n",
    "        ClassNetwork.train()\n",
    "        for i, data in enumerate(loaderTrain,0):\n",
    "            input, labels = data\n",
    "            input = input.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "   #         outputs = ClassNetwork(input, \"relu\")\n",
    "            loss = nn.MSELoss()\n",
    "            loss =loss(ClassNetwork(input, \"relu\"), labels)\n",
    "    # â¬… Backward pass + weight update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        for i, data in enumerate(loaderValid,0):\n",
    "            input, labels = data\n",
    "            input = input.to(device)\n",
    "            labels = labels.to(device)            \n",
    "            ClassNetwork.eval()\n",
    "            with torch.no_grad():\n",
    "                lossVal = nn.MSELoss()            \n",
    "                lossVal =lossVal(ClassNetwork(input, \"relu\"), labels)\n",
    "                RmsLossValid=torch.sqrt(lossVal) \n",
    "        \n",
    "        scheduler.step(RmsLossValid.item())            \n",
    "        print(\"epoch: \", epoch, \"loss: \", \"%.6f\" % loss.item() ,\"RmsLossValid: \" , \"%.6f\" % RmsLossValid.item())  \n",
    "        writer.add_scalar('Loss/train', loss.item(), epoch)\n",
    "        writer.add_scalar('RmsLossValid/valid', RmsLossValid.item(), epoch)\n",
    "        wandb.log({\"loss\": loss, \"RmsLossValid\": RmsLossValid})\n",
    "    data, labels = next(iter(loaderValid))\n",
    "    data = data.to(device)\n",
    "    labels = labels.to(device)    \n",
    "    writer.add_graph(ClassNetwork, data  )\n",
    "    writer.close\n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': ClassNetwork.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss,\n",
    "            \"RmsLossValid\": RmsLossValid\n",
    "            }, \"PaperModel.pt\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "source": [
    "\"\"\" ClassNetwork = Net()\n",
    "print(ClassNetwork)\n",
    "optimizer = optim.AdamW(ClassNetwork.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "loaderTrain, loaderValid =build_dataset(128,128)\n",
    "epochs = 8\n",
    "for epoch in range(epochs):\n",
    "    ClassNetwork.train()\n",
    "    for i, data in enumerate(loaderTrain,0):\n",
    "        input, labels = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = ClassNetwork(input, \"relu\")\n",
    "        loss = nn.MSELoss()\n",
    "        loss =loss(ClassNetwork(input, \"relu\"), labels)\n",
    "# â¬… Backward pass + weight update\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    for i, data in enumerate(loaderValid,0):\n",
    "        ClassNetwork.eval()\n",
    "        lossVal = nn.MSELoss()            \n",
    "        lossVal =lossVal(ClassNetwork(input, \"relu\"), labels)\n",
    "        RmsLossValid=torch.sqrt(loss) \n",
    "        scheduler.step(RmsLossValid)   \n",
    "    print(optimizer.param_groups[0][\"lr\"])\n",
    "    print(\"epoch: \", epoch, \"loss: \", \"%.4f\" % loss.item() ,\"RmsLossValid: \" , \"%.4f\" % RmsLossValid.item())  \n",
    " \"\"\""
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "' ClassNetwork = Net()\\nprint(ClassNetwork)\\noptimizer = optim.AdamW(ClassNetwork.parameters(), lr=0.001)\\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, \\'min\\')\\nloaderTrain, loaderValid =build_dataset(128,128)\\nepochs = 8\\nfor epoch in range(epochs):\\n    ClassNetwork.train()\\n    for i, data in enumerate(loaderTrain,0):\\n        input, labels = data\\n        optimizer.zero_grad()\\n        outputs = ClassNetwork(input, \"relu\")\\n        loss = nn.MSELoss()\\n        loss =loss(ClassNetwork(input, \"relu\"), labels)\\n# â¬… Backward pass + weight update\\n        loss.backward()\\n        optimizer.step()\\n    for i, data in enumerate(loaderValid,0):\\n        ClassNetwork.eval()\\n        lossVal = nn.MSELoss()            \\n        lossVal =lossVal(ClassNetwork(input, \"relu\"), labels)\\n        RmsLossValid=torch.sqrt(loss) \\n        scheduler.step(RmsLossValid)   \\n    print(optimizer.param_groups[0][\"lr\"])\\n    print(\"epoch: \", epoch, \"loss: \", \"%.4f\" % loss.item() ,\"RmsLossValid: \" , \"%.4f\" % RmsLossValid.item())  \\n '"
      ]
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "source": [
    "# ClassNetwork = Net()\n",
    "\n",
    "# loaderTrain, loaderValid =build_dataset(1024,1024)\n",
    "# data, labels = next(iter(loaderValid))\n",
    "# ClassNetwork( data, \"relu\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "source": [
    "train(config)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'Layer1': 2000, 'Layer2': 12}\n",
      "epoch:  0 loss:  0.001488 RmsLossValid:  0.045717\n",
      "epoch:  1 loss:  0.001771 RmsLossValid:  0.037547\n",
      "epoch:  2 loss:  0.000724 RmsLossValid:  0.034657\n",
      "epoch:  3 loss:  0.000916 RmsLossValid:  0.034765\n",
      "epoch:  4 loss:  0.000930 RmsLossValid:  0.032185\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5663/3976533758.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5663/805660924.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(config)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClassNetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m# â¬… Backward pass + weight update\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloaderValid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.2",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "643de512da3ef9692daa896915c9c6edbec44805ccf75c0ed51aafb5eb9790df"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}